{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting splinter\n",
      "  Using cached https://files.pythonhosted.org/packages/4e/33/6d6e3abeb0fa47284f2d3b74de7f72018a3af0267b0752b9e7c66175c99e/splinter-0.11.0.tar.gz\n",
      "Collecting selenium>=3.141.0 (from splinter)\n",
      "  Using cached https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six in c:\\users\\barbe\\appdata\\local\\continuum\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from splinter) (1.12.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\barbe\\appdata\\local\\continuum\\anaconda3\\envs\\deep_learning\\lib\\site-packages (from selenium>=3.141.0->splinter) (1.24.2)\n",
      "Building wheels for collected packages: splinter\n",
      "  Building wheel for splinter (setup.py): started\n",
      "  Building wheel for splinter (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\barbe\\AppData\\Local\\pip\\Cache\\wheels\\9c\\e1\\35\\4809427c48cb88853ddc1e701e9c5629bf192ae9324f2d0042\n",
      "Successfully built splinter\n",
      "Installing collected packages: selenium, splinter\n",
      "Successfully installed selenium-3.141.0 splinter-0.11.0\n"
     ]
    }
   ],
   "source": [
    "#Importing modules\n",
    "!pip install splinter\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from splinter import Browser\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pages_count(soup):\n",
    "    '''\n",
    "    Return the number of pages to visit for APA that contain dog information\n",
    "    \n",
    "    Params: soup --> BeautifulSoup object\n",
    "    \n",
    "    Return: pet_entry --> number of pages to iterate\n",
    "    '''\n",
    "    #Get the pagination division\n",
    "    pagination = soup.find('div', class_='pagination')\n",
    "    pages = list()\n",
    "    for page in pagination.find_all('a',class_='page'):\n",
    "        pages.append(page.text)\n",
    "    return(int(pages[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pet_info_by_url(soup):\n",
    "    '''\n",
    "    Parse the dog information into a dictionary to append to Mongo DB\n",
    "    \n",
    "    Params: soup --> BeautifulSoup object\n",
    "    \n",
    "    Return: pet_entry --> dictionary will all pat information\n",
    "    '''\n",
    "    #Main dictionary that will hold the data base entry\n",
    "    pet_entry = dict()\n",
    "    # Get all dog information\n",
    "    all_dogs_per_page = soup.find_all('div', class_='large-tile')\n",
    "    #Parse teh data\n",
    "    for dog in all_dogs_per_page:\n",
    "        #Dictonary used to store the data\n",
    "        pet_data = dict()\n",
    "        #Get the text based information\n",
    "        #[-] Name\n",
    "        pet_name = dog.find('h3').find('a').text\n",
    "        #[-] Id\n",
    "        pet_id = dog.find('h6').text\n",
    "        #[-] Listed information : Age, Sex, Breed\n",
    "        pet_info = dog.find('ul').find_all(\"li\")\n",
    "        #[--] Age , index 0\n",
    "        age_data = pet_info[0].text.split('Months')[0].split('Years')\n",
    "        #Conver the age in fraction of years\n",
    "        pet_age = round(int(age_data[0].strip()) + (int(age_data[1].strip()) /12.0),2)\n",
    "        #[--] Sex , index 1\n",
    "        pet_sex = pet_info[1].text\n",
    "        #[--] Breed , index 2\n",
    "        pet_breed = pet_info[2].text\n",
    "        #Build the data into the dictionary\n",
    "        #Get the pet dtats , we need to translate from stars to numbers\n",
    "        pet_location = pet_info[3].text\n",
    "        pet_data.update({'pet_name':pet_name})\n",
    "        pet_data.update({'pet_age':pet_age})\n",
    "        pet_data.update({'pet_sex':pet_sex})\n",
    "        pet_data.update({'pet_breed':pet_breed})\n",
    "        pet_data.update({'pet_location':pet_location})\n",
    "        #Count the starts to get the data\n",
    "        possible_stat_list = dog.find_all('div',class_='stats-panel')\n",
    "        for possible_stat in possible_stat_list:\n",
    "            stat = possible_stat.find_all('div',class_='flex')\n",
    "            for category in stat:\n",
    "                category_name = category.find('span',class_='stats-text').text\n",
    "                category_score = 0\n",
    "                stars = category.find_all('img')\n",
    "                for star in stars:\n",
    "                    if('star full' == star['alt']):\n",
    "                         category_score += 1\n",
    "                #Update the dictionary for each stat\n",
    "                pet_data.update({category_name:category_score})\n",
    "        #Update the main dictionary with the ID as main key and return\n",
    "        pet_entry.update({pet_id:pet_data})\n",
    "    return pet_entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_apa_data():\n",
    "    '''\n",
    "    Parse all dog information for APA dogs\n",
    "    \n",
    "    Params: None\n",
    "    \n",
    "    Return: pet_entry --> dictionary with the information\n",
    "    '''\n",
    "    #main page for DOG adoption APA\n",
    "    main_url = url = 'https://www.austinpetsalive.org/adopt/dogs'\n",
    "    #Base url to add the page to scrape\n",
    "    bas_url_4_page = 'https://www.austinpetsalive.org/adopt/dogs/p'\n",
    "    #Dictionary used to store all the data scraped\n",
    "    pet_data = dict()\n",
    "    #create the browser object\n",
    "    executable_path = {'executable_path': 'chromedriver'}\n",
    "    browser = Browser('chrome', **executable_path, headless=False)\n",
    "    #Create the defult list of URLs to vist and add the first page\n",
    "    url_list = list(main_url)\n",
    "    #Visit the main page to collect number of pages and the first data scrape\n",
    "    browser.visit(main_url)\n",
    "    # Create BeautifulSoup object; parse with 'html.parser'\n",
    "    soup = BeautifulSoup(browser.html, 'html.parser')\n",
    "    #Get the number fo pages to scrape besides the main one\n",
    "    total_pages = get_pages_count(soup)\n",
    "    #Update the data of the main entry page\n",
    "    pet_data.update(get_pet_info_by_url(soup))\n",
    "    #Iterate over the next pages to get the complete data, we start in 2 bacause\n",
    "    #index 1 is the pain page\n",
    "    for page_idx in range(2,total_pages+1):\n",
    "        #Build the new page\n",
    "        page_url = bas_url_4_page + str(page_idx)\n",
    "        #Visit the new page\n",
    "        browser.visit(page_url)\n",
    "        #parse teh data\n",
    "        soup = BeautifulSoup(browser.html, 'html.parser')\n",
    "        #Update the information\n",
    "        pet_data.update(get_pet_info_by_url(soup))\n",
    "   \n",
    "    #Clos ethe browser\n",
    "    browser.quit()\n",
    "    return pet_data\n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Scrape the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: 'chromedriver' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\selenium\\webdriver\\common\\service.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     75\u001b[0m                                             \u001b[0mstderr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                                             stdin=PIPE)\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\deep_learning\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    774\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 775\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    776\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\deep_learning\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1177\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m   1179\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-706f5ac8b593>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Get the information\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mapa_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_all_apa_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-db041b9ffa8e>\u001b[0m in \u001b[0;36mget_all_apa_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m#create the browser object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mexecutable_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'executable_path'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'chromedriver'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mbrowser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBrowser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'chrome'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mexecutable_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheadless\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[1;31m#Create the defult list of URLs to vist and add the first page\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0murl_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\splinter\\browser.py\u001b[0m in \u001b[0;36mBrowser\u001b[1;34m(driver_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mDriverNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No driver for %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdriver_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\splinter\\driver\\webdriver\\chrome.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, options, user_agent, wait_time, fullscreen, incognito, headless, **kwargs)\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"--disable-gpu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdriver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mChrome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melement_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWebDriverElement\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\selenium\\webdriver\\chrome\\webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, keep_alive)\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[0mservice_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mservice_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             log_path=service_log_path)\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\selenium\\webdriver\\common\\service.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     81\u001b[0m                 raise WebDriverException(\n\u001b[0;32m     82\u001b[0m                     \"'%s' executable needs to be in PATH. %s\" % (\n\u001b[1;32m---> 83\u001b[1;33m                         os.path.basename(self.path), self.start_error_message)\n\u001b[0m\u001b[0;32m     84\u001b[0m                 )\n\u001b[0;32m     85\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEACCES\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: 'chromedriver' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home\n"
     ]
    }
   ],
   "source": [
    "#Get the information\n",
    "apa_data = get_all_apa_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'apa_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-21d33d834c78>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Display the information\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mapa_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'apa_data' is not defined"
     ]
    }
   ],
   "source": [
    "#Display the information\n",
    "apa_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'apa_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-5fe85eb1809c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Get the number of entries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapa_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'apa_data' is not defined"
     ]
    }
   ],
   "source": [
    "#Get the number of entries\n",
    "len(apa_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
